{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f977338",
   "metadata": {},
   "source": [
    "#  Logistic Regression in KDB+\n",
    "\n",
    "## Find sentiment of tweet (Binary Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "c6a1f6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_p: read0 `:./../data/twitter_samples/positive_tweets.json\n",
    "t_n: read0 `:./../data/twitter_samples/negative_tweets.json\n",
    "/ t_p -> tweet positive\n",
    "/ t_n -> tweet negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b768eb59",
   "metadata": {},
   "source": [
    "### Prepare the data\n",
    "* The `twitter_samples` contains subsets of five thousand positive_tweets, five thousand negative_tweets, and the full set of 10,000 tweets.  \n",
    "\n",
    "* 8000 Data for testing\n",
    "* 2000 Data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "2b1e5365",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive : ((uj/) {enlist .j.k raze t_p[x]}'[til count t_p])\n",
    "update sentiment:1 from `df_positive;\n",
    "df_positive : 4000#select text, sentiment from df_positive;\n",
    "df_test1:-1000#select text, sentiment from df_positive;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "477ef29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative:(((uj/) {enlist .j.k raze t_n[x]}'[til count t_n]))\n",
    "update sentiment:0 from `df_negative;\n",
    "df_negative: 4000#select text, sentiment from df_negative;\n",
    "df_test2: -1000#select text, sentiment from df_negative;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "def96fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df: df_positive uj df_negative;\n",
    "df_test: df_test1 uj df_test2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "4f54436f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`.\n"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete df_negative,df_positive,t_n,t_p from `."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "896f8f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`J`X`Y`df`df_test`df_test1`df_test2`freqs`h`m`punctuations`res`stop_words`the..\n"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\\v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "fdf46819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000\n"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "d0a61bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "/ Stop words\n",
    "stop_words:read0 `:./../data/english\n",
    "\n",
    "/preprocessing\n",
    "stemmer:{\n",
    "    suffixes : (\"*ing\";\"*ly\";\"*ness\";\"*ed\";\"*ious\";\"*ies\";\"*ive\";\"*es\";\"*ment\";\"*s\");\n",
    "    if[(count x) < 3; :(x); :(::)];\n",
    "    suf: suffixes where ((x like/:) suffixes);\n",
    "    x: (1 - (count each suf))[0] _ x;\n",
    "    :x\n",
    "    };\n",
    "\n",
    "punctuations:\"!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~\";\n",
    "\n",
    "/Make word frequency dictionary\n",
    "mkdic:{[d;x]$[x in key d;d[x]+:1;d[x]:1];d};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "f2672caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fun:{[df]\n",
    "    w:()!();\n",
    "    v:()!();\n",
    "    pos_lis: \" \" sv lower(exec text from df where sentiment = 1);\n",
    "    neg_lis: \" \" sv lower(exec text from df where sentiment = 0);\n",
    "    pos_lis: pos_lis except punctuations;\n",
    "    neg_lis: neg_lis except punctuations;\n",
    "    pos_lis:\" \" vs lower(pos_lis);\n",
    "    neg_lis:\" \" vs lower(neg_lis);\n",
    "    pos_lis: (pos_lis except stop_words);\n",
    "    neg_lis: (neg_lis except stop_words);\n",
    "    pos_lis:{.[stemmer;enlist x;x]}'[pos_lis];\n",
    "    neg_lis:{.[stemmer;enlist x;x]}'[neg_lis];\n",
    "    pos_lis: `$pos_lis;\n",
    "    neg_lis:`$neg_lis;\n",
    "    w:mkdic/[w;pos_lis];\n",
    "    v:mkdic/[v;neg_lis];\n",
    "    pos_t: ([word:key w]; pos:value w);\n",
    "    neg_t: ([word:key v]; negv:value v);\n",
    "    .Q.gc[];\n",
    "    :0!(0^(pos_t uj neg_t))\n",
    "    };"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd239ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2b16c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "8e662c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs: fun df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "4d5bf237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word         pos  negv\n",
       "----------------------\n",
       "followfriday 23   0   \n",
       "franceinte   1    0   \n",
       "pkuchly57    1    0   \n",
       "milipolpari  1    0   \n",
       "top          29   4   \n",
       "engag        7    0   \n",
       "member       13   6   \n",
       "community    25   1   \n",
       "week         73   47  \n",
       "             4227 4540\n",
       "lamb2ja      1    0   \n",
       "hey          58   20  \n",
       "jam          7    4   \n",
       "odd          2    2   \n",
       "please       77   203 \n",
       "call         28   22  \n",
       "contact      4    7   \n",
       "centre       1    1   \n",
       "02392441234  1    0   \n",
       "able         6    17  \n",
       "..\n"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f8aced",
   "metadata": {},
   "source": [
    "### Logistic regression: regression and a sigmoid\n",
    "\n",
    "Logistic regression takes a regular linear regression, and applies a sigmoid to the output of the linear regression.\n",
    "\n",
    "Regression:\n",
    "$$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$\n",
    "Note that the $\\theta$ values are \"weights\". If you took the deep learning specialization, we referred to the weights with the 'w' vector.  In this course, we're using a different variable $\\theta$ to refer to the weights.\n",
    "\n",
    "Logistic regression\n",
    "$$ h(z) = \\frac{1}{1+\\exp^{-z}}$$\n",
    "$$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$\n",
    "We will refer to 'z' as the 'logits'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "6a2b7dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid:{\n",
    "    :(1%(1+(2.718281828459045 xexp (neg x))))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850bebca",
   "metadata": {},
   "source": [
    "## Implement gradient descent function\n",
    "* The number of iterations 'num_iters\" is the number of times that you'll use the entire training set.\n",
    "* For each iteration, you'll calculate the cost function using all training examples (there are 'm' training examples), and for all features.\n",
    "* Instead of updating a single weight $\\theta_i$ at a time, we can update all the weights in the column vector:  \n",
    "$$\\mathbf{\\theta} = \\begin{pmatrix}\n",
    "\\theta_0\n",
    "\\\\\n",
    "\\theta_1\n",
    "\\\\ \n",
    "\\theta_2 \n",
    "\\\\ \n",
    "\\vdots\n",
    "\\\\ \n",
    "\\theta_n\n",
    "\\end{pmatrix}$$\n",
    "* $\\mathbf{\\theta}$ has dimensions (n+1, 1), where 'n' is the number of features, and there is one more element for the bias term $\\theta_0$ (note that the corresponding feature value $\\mathbf{x_0}$ is 1).\n",
    "* The 'logits', 'z', are calculated by multiplying the feature matrix 'x' with the weight vector 'theta'.  $z = \\mathbf{x}\\mathbf{\\theta}$\n",
    "    * $\\mathbf{x}$ has dimensions (m, n+1) \n",
    "    * $\\mathbf{\\theta}$: has dimensions (n+1, 1)\n",
    "    * $\\mathbf{z}$: has dimensions (m, 1)\n",
    "* The prediction 'h', is calculated by applying the sigmoid to each element in 'z': $h(z) = sigmoid(z)$, and has dimensions (m,1).\n",
    "* The cost function $J$ is calculated by taking the dot product of the vectors 'y' and 'log(h)'.  Since both 'y' and 'h' are column vectors (m,1), transpose the vector to the left, so that matrix multiplication of a row vector with column vector performs the dot product.\n",
    "$$J = \\frac{-1}{m} \\times \\left(\\mathbf{y}^T \\cdot log(\\mathbf{h}) + \\mathbf{(1-y)}^T \\cdot log(\\mathbf{1-h}) \\right)$$\n",
    "* The update of theta is also vectorized.  Because the dimensions of $\\mathbf{x}$ are (m, n+1), and both $\\mathbf{h}$ and $\\mathbf{y}$ are (m, 1), we need to transpose the $\\mathbf{x}$ and place it on the left in order to perform matrix multiplication, which then yields the (n+1, 1) answer we need:\n",
    "$$\\mathbf{\\theta} = \\mathbf{\\theta} - \\frac{\\alpha}{m} \\times \\left( \\mathbf{x}^T \\cdot \\left( \\mathbf{h-y} \\right) \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "9642e861",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradientDescent:{[x;y;theta;alpha;num_iters] \n",
    "    m : count x;\n",
    "    J : 0;\n",
    "    do[num_iters;\n",
    "        z : x$theta;\n",
    "        h : sigmoid z;\n",
    "        J : (neg 1 % m) * (((y)$log h) + (((1-y))$(log (1-h))));\n",
    "        theta : theta - (1e-8 % m)*((flip x)$(h-y));\n",
    "        ];\n",
    "    J = \"f\"$J;\n",
    "    :(J;theta)\n",
    "    };\n",
    "\n",
    "/ Make sure theta should be float (0.0; 0.0; 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "1148e83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "/x: ((1.00000000e+00 8.34044009e+02 1.44064899e+03);(1.00000000e+00 2.28749635e-01 6.04665145e+02);(1.00000000e+00 2.93511782e+02 1.84677190e+02);(1.00000000e+00 3.72520423e+02 6.91121454e+02);(1.00000000e+00 7.93534948e+02 1.07763347e+03);(1.00000000e+00 8.38389029e+02 1.37043900e+03);(1.00000000e+00 4.08904499e+02 1.75623487e+03);(1.00000000e+00 5.47751864e+01 1.34093502e+03);(1.00000000e+00 8.34609605e+02 1.11737966e+03);(1.00000000e+00 2.80773877e+02 3.96202978e+02));\n",
    "/y : ((1.);(1.);(0.);(1.);(1.);(1.);(0.);(0.);(0.);(1.));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "8b86552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "/gradientDescent[x;y;((0.0);(0.0);(0.0));1e-8;700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779caa26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "6793466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "/Function for get word's positive count and negative count.\n",
    "get_pos_val:{\n",
    "    v:exec pos from freqs where word=x;\n",
    "    $[count v; v[0];0]\n",
    "    };\n",
    "\n",
    "get_neg_val:{\n",
    "    v:exec negv from freqs where word=x;\n",
    "    $[count v; v[0];0]\n",
    "    };"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c366b56",
   "metadata": {},
   "source": [
    "## Process tweet\n",
    "\n",
    "The process_tweet function will return the list of processed tweet words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "40ddf055",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_tweet:{\n",
    "    x: x except punctuations;\n",
    "    x: \" \" vs lower(x);\n",
    "    x: x except stop_words;\n",
    "    x: {.[stemmer;enlist x;x]}'[x];\n",
    "    :`$x\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "d720f286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`today`go`good`day\n"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_tweet \"Today is going to be a good day\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9196ae15",
   "metadata": {},
   "source": [
    "## Extracting the features\n",
    "\n",
    "* Given a list of tweets, extract the features and store them in a matrix. You will extract two features.\n",
    "    * The first feature is the number of positive words in a tweet.\n",
    "    * The second feature is the number of negative words in a tweet. \n",
    "* Then train your logistic regression classifier on these features.\n",
    "* Test the classifier on a validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "4b2d9a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features:{[tweet]\n",
    "    word_l: process_tweet[tweet];\n",
    "    theta: (0.0;0.0;0.0);\n",
    "    theta[1]:`float$(sum {get_pos_val x}'[word_l]);\n",
    "    theta[2]:`float$(sum {get_neg_val x}'[word_l]);\n",
    "    :theta;\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "d8d4040a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0 65 21f\n"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_features \"Hello word!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28771577",
   "metadata": {},
   "source": [
    "## Training Model\n",
    "\n",
    "To train the model:\n",
    "* Stack the features for all training examples into a matrix X. \n",
    "* Call `gradientDescent`, which you've implemented above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "d62c2682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`df\n"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update feature:extract_features'[text] from `df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "deb19bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X : exec feature from df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "3ac0b302",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y : `float$(exec sentiment from df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "768aed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res: gradientDescent[X;Y;(0.0;0.0;0.0);1e-9;1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "0943923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "J : res[0]\n",
    "theta: res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "b3d3990d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_tweet:{[tweet]\n",
    "    x:extract_features[tweet];\n",
    "    :sigmoid[x mmu theta]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d24474",
   "metadata": {},
   "source": [
    "## Predict Tweet\n",
    "\n",
    "Predict tweet function will return the sigmoid value of given word. \n",
    "\n",
    "* value > 0.5 ---> Positive\n",
    "* value < 0.5 ---> Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "c00a9047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5038576\n"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_tweet[\"Hello world!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "35bdddef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`df_test\n"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update y_pred:predict_tweet'[text] > 0.5 from `df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "5a99f6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y_pred\n",
       "------\n",
       "0.6505\n"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select sum(sentiment=y_pred)% 2000 from df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cffadaa",
   "metadata": {},
   "source": [
    "#### The accuracy score is 65.05 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3100b392",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Q (kdb+)",
   "language": "q",
   "name": "qpk"
  },
  "language_info": {
   "file_extension": ".q",
   "mimetype": "text/x-q",
   "name": "q",
   "version": "4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
